# ğŸ•¸ï¸ Web Scraping con Databricks + PySpark: Casos PrÃ¡cticos

Este repositorio demuestra cÃ³mo realizar **web scraping** en un entorno **Databricks**, utilizando Python (`requests`, `BeautifulSoup`) para extraer datos de pÃ¡ginas web y transformarlos en **DataFrames de PySpark** para su posterior anÃ¡lisis.

---

## ğŸ¯ Objetivo

Explorar tÃ©cnicas de scraping ejecutables directamente desde notebooks en Databricks, sin necesidad de renderizado JavaScript o herramientas como Selenium. Ideal para entornos de datos donde se requiere automatizar la captura de contenido web estructurado.

---

## ğŸ“š Casos incluidos

### ğŸ”¹ VersiÃ³n 1: Scraping HTML estÃ¡tico
- **Sitio web:** [quotes.toscrape.com](https://quotes.toscrape.com)
- **DescripciÃ³n:** Extrae frases de ejemplo desde una pÃ¡gina HTML simple y las carga como DataFrame.
- **TecnologÃ­as:** `requests`, `BeautifulSoup`, `PySpark`

### ğŸ”¹ VersiÃ³n 2: Scraping desde Google Sheets pÃºblica
- **Fuente:** Google Sheets publicada como HTML
- **URL:** [Ver hoja de ejemplo](https://docs.google.com/spreadsheets/d/e/2PACX-1vQzWjN8VvkgwCAffEnVvtt-otYKC3NCUKmWtC47CmKc-r9TJKjNfnkacij9C2wE_A/pubhtml)
- **DescripciÃ³n:** Extrae filas de una hoja pÃºblica en Google Sheets y las convierte en un DataFrame.

---

## ğŸ§ª TecnologÃ­as utilizadas

- **Databricks (entorno notebook)**
- **Python 3**
- `requests` â€“ para obtener el HTML de las pÃ¡ginas web  
- `beautifulsoup4` â€“ para parsear y extraer datos del HTML  
- `PySpark` â€“ para transformar los datos en DataFrames y visualizarlos

---

## âš™ï¸ InstalaciÃ³n de dependencias

Ejecuta en una celda de tu notebook Databricks:

```python
%pip install requests beautifulsoup4
